<!DOCTYPE html>
<html>
<head>
    <title>Project 1</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg: #f5f7fb;
            --text: #0f172a;
            --muted: #475569;
            --border: rgba(255,255,255,0.35);
            --accent: #2563eb;
            --glass-bg: rgba(255,255,255,0.45);
            --glass-shadow: 0 10px 30px rgba(2,6,23,0.08);
        }
        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Arial, sans-serif;
            margin: 0;
            line-height: 1.65;
            color: var(--text);
            background: var(--bg);
            text-align: center;
        }
        .container { max-width: 1200px; margin: 0 auto; padding: 32px 20px; }
        header { margin-bottom: 20px; padding: 16px; border-radius: 16px; display: flex; align-items: center; gap: 12px; }
        header h1 { margin: 0; font-size: 32px; }
        header p { margin: 6px 0 0; color: var(--text); }
        nav a { color: var(--accent); text-decoration: none; }
        nav a:hover { text-decoration: underline; }
        .glass {
            position: relative;
            border-radius: 18px;
            border: 1px solid transparent;
            background-image:
                linear-gradient(135deg, rgba(255,255,255,0.55), rgba(255,255,255,0.25)),
                linear-gradient(135deg, rgba(255,255,255,0.85), rgba(17,24,39,0.08));
            background-origin: padding-box, border-box;
            background-clip: padding-box, border-box;
            box-shadow: var(--glass-shadow);
            -webkit-backdrop-filter: blur(16px) saturate(180%);
            backdrop-filter: blur(16px) saturate(180%);
        }
        /* Ensure overlays sit behind content to avoid lightening text */
        .glass > * { position: relative; z-index: 1; }
        .glass::before {
            content: "";
            position: absolute;
            inset: 1px;
            border-radius: inherit;
            pointer-events: none;
            background: radial-gradient(120% 80% at 0% 0%, rgba(255,255,255,0.65), rgba(255,255,255,0) 60%);
            mix-blend-mode: screen;
            z-index: 0;
        }
        .glass::after {
            content: "";
            position: absolute;
            inset: 0;
            border-radius: inherit;
            pointer-events: none;
            box-shadow: inset 0 1px 0 rgba(255,255,255,0.6), inset 0 -1px 0 rgba(255,255,255,0.35), inset 0 0 40px rgba(255,255,255,0.12);
            z-index: 0;
        }
        .card { padding: 20px; margin: 20px 0; text-align: left; }
        .muted { color: var(--muted); }
        ul { margin: 0.5rem 0 0.5rem 1.25rem; }
        li { margin: 0.25rem 0; }
        .two-up { display: flex; gap: 12px; justify-content: center; align-items: flex-start; margin-top: 12px; }
        .two-up img { flex: 1 1 0; min-width: 0; width: 100%; height: auto; border-radius: 18px; }
        .two-up .compare { flex: 1 1 0; max-width: none; }
        .two-up.hero { align-items: center; justify-content: center; position: relative; }
        .two-up.hero::after { content: 'Click to expand'; position: absolute; right: 8px; bottom: 8px; background: rgba(15,23,42,0.7); color: #fff; padding: 4px 8px; border-radius: 999px; font-size: 12px; opacity: 0; transition: opacity 0.2s ease; pointer-events: none; }
        .two-up.hero:hover::after { opacity: 1; }
        .two-up.hero img { flex: 0 0 30%; max-width: 30%; max-height: 360px; height: auto; object-fit: contain; }
        @media (max-width: 640px) {
            .two-up.hero { flex-direction: column; }
            .two-up.hero .arrow { display: none; }
            .two-up.hero img { max-width: 100%; width: 100%; }
        }
        .two-up .arrow { flex: 0 0 auto; display: flex; align-items: center; justify-content: center; font-size: 28px; padding: 0 8px; color: var(--text); }
        .placeholder {
            height: 240px;
            border: 1px dashed var(--border);
            background: #f8fafc;
            border-radius: 8px;
            display: flex;
            align-items: center;
            justify-content: center;
            color: var(--muted);
            margin-top: 12px;
        }
        .formula { text-align: center; font-size: 18px; margin: 8px 0; }
        /* Before/After Slider */
        .compare { position: relative; width: 100%; max-width: 900px; margin: 12px auto 0; border-radius: 12px; overflow: hidden; box-shadow: var(--glass-shadow); }
        .compare-base, .compare-overlay img { display: block; width: 100%; height: auto; user-select: none; }
        .compare-overlay { position: absolute; inset: 0; overflow: hidden; will-change: clip-path; }
        .compare-handle { position: absolute; top: 0; bottom: 0; left: 50%; width: 2px; background: rgba(255,255,255,0.9); box-shadow: 0 0 0 1px rgba(15,23,42,0.35); cursor: ew-resize; }
        .compare-handle::before { content: ""; position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); width: 18px; height: 18px; border-radius: 50%; background: rgba(255,255,255,0.95); box-shadow: 0 1px 2px rgba(15,23,42,0.2), 0 0 0 1px rgba(15,23,42,0.25); }
        .compare-label { position: absolute; top: 8px; padding: 4px 8px; background: rgba(15,23,42,0.6); color: #fff; border-radius: 999px; font-size: 12px; }
        .compare-label.left { left: 8px; }
        .compare-label.right { right: 8px; }
        .compare::after { content: 'Click to expand'; position: absolute; right: 8px; bottom: 8px; background: rgba(15,23,42,0.7); color: #fff; padding: 4px 8px; border-radius: 999px; font-size: 12px; opacity: 0; transition: opacity 0.2s ease; pointer-events: none; }
        .compare:hover::after { opacity: 1; }
        /* Results grid */
        .grid { display: grid; grid-template-columns: repeat(4, 1fr); gap: 10px; margin-top: 12px; }
        .grid figure { margin: 0; position: relative; }
        .grid img { width: 100%; height: auto; border-radius: 10px; display: block; transition: transform 0.2s ease, box-shadow 0.2s ease; }
        .grid figcaption { text-align: center; font-size: 12px; color: var(--muted); margin-top: 4px; }
        .grid figure::after { content: 'Click to expand'; position: absolute; right: 8px; bottom: 8px; background: rgba(15,23,42,0.7); color: #fff; padding: 4px 8px; border-radius: 999px; font-size: 12px; opacity: 0; transition: opacity 0.2s ease; pointer-events: none; }
        .grid figure:hover::after { opacity: 1; }
        .grid figure:hover img { transform: scale(1.02); box-shadow: 0 8px 24px rgba(15,23,42,0.2); }
        @media (max-width: 900px) { .grid { grid-template-columns: repeat(3, 1fr); } }
        @media (max-width: 640px) { .grid { grid-template-columns: repeat(2, 1fr); } }
        /* Tables */
        .table { width: 100%; border-collapse: collapse; margin-top: 12px; }
        .table th, .table td { border: 1px solid var(--border); padding: 6px 8px; text-align: left; }
        .table thead th { background: rgba(15,23,42,0.04); }
        .table-slim { font-size: 13px; }
        /* Lightbox */
        .lightbox { position: fixed; inset: 0; background: rgba(15,23,42,0.8); display: none; align-items: center; justify-content: center; z-index: 1000; }
        .lightbox.open { display: flex; }
        .lightbox img { max-width: 92vw; max-height: 92vh; border-radius: 12px; box-shadow: 0 20px 60px rgba(0,0,0,0.35); }
        .lightbox .close { position: absolute; top: 16px; right: 16px; background: #ffffff; border: none; border-radius: 999px; width: 36px; height: 36px; cursor: pointer; font-size: 20px; box-shadow: 0 2px 6px rgba(0,0,0,0.25); }
        .grid img, .compare img, .two-up.hero img, .expandable { cursor: zoom-in; }
        .compare:hover img { filter: brightness(0.98); }
        /* Zoomed compare (cropped cutout without rescaling images differently) */
        .compare.zoom { height: 360px; }
        .compare.zoom .compare-base, .compare.zoom .compare-overlay img { height: 100%; width: auto; transform: scale(var(--zoom,3)); transform-origin: var(--origin, 50% 50%); }
        /* Print-friendly overrides */
        @media print {
            @page { size: auto; margin: 12mm; }
            html, body { background: #ffffff !important; color: #000000 !important; }
            body { -webkit-print-color-adjust: exact; print-color-adjust: exact; }
            .container { max-width: none; padding: 0; }
            header.glass, .card.glass {
                background: #ffffff !important;
                background-image: none !important;
                border: 1px solid #cccccc !important;
                box-shadow: none !important;
                -webkit-backdrop-filter: none !important;
                backdrop-filter: none !important;
            }
            nav a { color: #000000 !important; text-decoration: underline; }
        }
    </style>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta charset="utf-8" />
    <meta name="description" content="Project 1 - Colorizing the Prokudin-Gorskii photo collection" />
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head>
<body>
    <div class="container">
        <header class="glass">
            <img src="../logo.png" alt="UC Berkeley logo" style="height:64px;width:auto;" />
            <div style="text-align:left;">
                <h1>Programming Project #1 (proj1)</h1>
                <p>CS180: Intro to Computer Vision and Computational Photography</p>
            </div>
            <nav style="margin-left:auto;"><a href="../index.html">‚Üê Back to Home</a></nav>
        </header>

        <section class="card glass">
            <h2>Images of the Russian Empire: Colorizing the Prokudin-Gorskii photo collection</h2>
            <div class="two-up hero" aria-label="Unaligned versus aligned example">
                <img src="./example_unaligned.jpg" alt="Unaligned stacked color channels" />
                <div class="arrow" aria-hidden="true">‚Üí</div>
                <img src="./example_aligned.png" alt="Aligned color image" />
            </div>
        </section>

        

        <section class="card glass">
            <h2>Approach (High-Level)</h2>
            <p><strong>Goal</strong>: Reconstruct a clean color image by extracting the three monochrome plates (B, G, R), aligning them precisely, and stacking them into an RGB image with minimal artifacts.</p>
            <p>
                I first inspected the input plates. There is clear correlation across channels at the same pixel
                locations: brighter pixels in one channel are usually brighter in the others (not always, but mostly).
                However, overall illumination and contrast differ between channels, so raw intensities are on different
                scales.
            </p>
            <p>
                This suggested using a pixelwise distance metric to quantify alignment quality: if the plates are well
                aligned, the sum of per-pixel distances should be small. To avoid getting stuck in local minima (which
                can happen if you only move greedily in the locally best direction), I evaluate the total distance for
                many candidate shifts and choose the shift with the lowest global score.
            </p>
            <p>
                I started with an exhaustive search over translations using the <strong>L2 distance</strong> on raw pixel values.
                This already produced good alignments for many images. However, some cases like the <em>emir</em> still failed
                due to cross‚Äëchannel brightness differences, for example clearly visible in his very colorful dress.
            </p>
            <p>
                I first tried per‚Äëchannel min‚Äìmax scaling to normalize dynamic range, but results were unstable since
                extrema are image‚Äëdependent and sensitive to outliers. I then switched to per‚Äëchannel
                <strong>z‚Äënormalization</strong> (standardizing to zero mean and unit variance) before scoring so that structures
                became more comparable across channels despite overall brightness/gain differences.
            </p>
            <p><strong>L2 distance</strong> between two patches/channels I and J:</p>
            <div class="formula">\[ \|I - J\|_2 = \sqrt{\sum_i (I_i - J_i)^2} \]</div>
            <p><strong>Z-normalization</strong> of a channel X:</p>
            <div class="formula">\[ z(x) = \frac{x - \mu}{\sigma} \quad \text{where } \mu = \mathrm{mean}(X),\; \sigma = \mathrm{std}(X) \]</div>
            <p>
                Despite z‚Äënormalization, a few images remained challenging. I therefore added
                <strong>Normalized Cross‚ÄëCorrelation (NCC)</strong> as the matching score. Intuition: NCC compares
                zero‚Äëmean, normalized patches and is invariant to linear brightness/contrast changes, making it better
                suited when channels have different gains.
            </p>
            <div class="formula">\[ \mathrm{NCC}(I, J) = \frac{\sum_i (I_i - \bar I)(J_i - \bar J)}{\sqrt{\sum_i (I_i - \bar I)^2}\;\sqrt{\sum_i (J_i - \bar J)^2}} \]</div>
            <p>
                In practice, I z‚Äënormalize or zero‚Äëcenter patches and evaluate NCC over a search window derived by
                splitting each channel into a small grid of patches; I score candidate shifts across these windows and
                take the displacement with the highest overall score. This made the alignment robust across all images,
                including difficult cases like the emir.
            </p>
            <h3>Low‚Äëresolution results (JPEG, brute force)</h3>
            
            <div class="grid">
                <figure><img src="./1/jpeg/cathedral.png" alt="cathedral (JPEG brute force)" /><figcaption>cathedral (JPEG)</figcaption></figure>
                <figure><img src="./1/jpeg/monastery.png" alt="monastery (JPEG brute force)" /><figcaption>monastery (JPEG)</figcaption></figure>
                <figure><img src="./1/jpeg/tobolsk.png" alt="tobolsk (JPEG brute force)" /><figcaption>tobolsk (JPEG)</figcaption></figure>
            </div>
            <p class="muted">However, because high‚Äëresolution TIFFs are also available, a faster approach is needed for those larger images.</p>
            
            <h3>Coarse‚Äëto‚ÄëFine Pyramid</h3>
            
            <p>
                To make alignment efficient on large glass plates, I use a multi-scale (coarse‚Äëto‚Äëfine) image pyramid:
            </p>
            <p><strong>Intuition</strong>: Computing scores (e.g., L2, NCC) over many shifts on full‚Äëresolution images is expensive. Start at a much smaller resolution to get a cheap, rough alignment; then iteratively double the size and refine around that estimate. This minimizes the total number of evaluations overall, with only a few refinements needed at full resolution.</p>
            <img src="./pyramid.png" alt="Coarse-to-fine image pyramid visualization" style="display:block;margin:12px auto;max-width:100%;height:auto;border-radius:12px;" />
            <p style="text-align:center;margin:4px 0 0;">
                <small>Source: <a href="https://iipimage.sourceforge.io/documentation/images/" target="_blank" rel="noopener noreferrer">IIPImage documentation</a></small>
            </p>
            <ol>
                <li>Build a pyramid by halving resolution until another downscale would make the smallest dimension &lt; 32 px (min base ‚âà 32√ó32).</li>
                <li>At the coarsest level, stack the channels and run an exhaustive search with a ¬±8 px radius to find the best translation.</li>
                <li>Propagate the displacement to the next finer level (scale √ó2), then refine within a small local window of ¬±2 px (top/bottom/left/right).</li>
                <li>Repeat to full resolution, optionally re‚Äënormalizing and scoring on interior pixels to avoid border effects.</li>
            </ol>
            <p class="muted">NCC windowing: at the smallest level I split the image into a 2√ó2 grid and evaluated NCC per cell; at the next level (2√ó bigger) into a 4√ó4 grid, and so on. This keeps the NCC window size approximately constant in absolute terms across scales.</p>
            <p>
                Using a larger window (¬±8) only at the coarsest level and a tighter window (¬±2) at finer levels dramatically reduces the global search space while preserving final alignment accuracy.
            </p>
            <h3>Results (Aligned RGB, high‚Äëres TIFF, pyramid)</h3>
            <p class="muted">Outputs produced on the high‚Äëresolution TIFFs using the coarse‚Äëto‚Äëfine alignment and per‚Äëchannel min‚Äìmax rendering.</p>
            <div class="grid">
                <figure><img src="./1/tiff/church.png" alt="church (TIFF pyramid)" /><figcaption>church (TIFF)</figcaption></figure>
                <figure><img src="./1/tiff/emir.png" alt="emir (TIFF pyramid)" /><figcaption>emir (TIFF)</figcaption></figure>
                <figure><img src="./1/tiff/harvesters.png" alt="harvesters (TIFF pyramid)" /><figcaption>harvesters (TIFF)</figcaption></figure>
                <figure><img src="./1/tiff/icon.png" alt="icon (TIFF pyramid)" /><figcaption>icon (TIFF)</figcaption></figure>
                <figure><img src="./1/tiff/italil.png" alt="italil (TIFF pyramid)" /><figcaption>italil (TIFF)</figcaption></figure>
                <figure><img src="./1/tiff/lastochikino.png" alt="lastochikino (TIFF pyramid)" /><figcaption>lastochikino (TIFF)</figcaption></figure>
                <figure><img src="./1/tiff/lugano.png" alt="lugano (TIFF pyramid)" /><figcaption>lugano (TIFF)</figcaption></figure>
                <figure><img src="./1/tiff/melons.png" alt="melons (TIFF pyramid)" /><figcaption>melons (TIFF)</figcaption></figure>
                <figure><img src="./1/tiff/self_portrait.png" alt="self_portrait (TIFF pyramid)" /><figcaption>self_portrait (TIFF)</figcaption></figure>
                <figure><img src="./1/tiff/siren.png" alt="siren (TIFF pyramid)" /><figcaption>siren (TIFF)</figcaption></figure>
                <figure><img src="./1/tiff/three_generations.png" alt="three_generations (TIFF pyramid)" /><figcaption>three_generations (TIFF)</figcaption></figure>
            </div>
            <h4 style="margin-top:16px;">Alignment Offsets and Compute Times (Combined L2 + NCC)</h4>
            
            <table class="table table-slim">
                <thead>
                    <tr>
                        <th>Image</th>
                        <th>B‚ÜíG shift</th>
                        <th>R‚ÜíG shift</th>
                        <th style="text-align:right;">Total time (s)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td>cathedral</td><td>up 5 px, left 2 px</td><td>down 7 px, right 1 px</td><td style="text-align:right;">0.388</td></tr>
                    <tr><td>church</td><td>up 25 px, left 4 px</td><td>down 33 px, left 8 px</td><td style="text-align:right;">30.243</td></tr>
                    <tr><td>emir</td><td>up 49 px, left 22 px</td><td>down 57 px, right 18 px</td><td style="text-align:right;">30.524</td></tr>
                    <tr><td>harvesters</td><td>up 59 px, left 16 px</td><td>down 64 px, left 2 px</td><td style="text-align:right;">30.019</td></tr>
                    <tr><td>icon</td><td>up 39 px, left 17 px</td><td>down 48 px, right 5 px</td><td style="text-align:right;">30.702</td></tr>
                    <tr><td>italil</td><td>up 38 px, left 21 px</td><td>down 39 px, right 15 px</td><td style="text-align:right;">30.655</td></tr>
                    <tr><td>lastochikino</td><td>down 2 px, right 2 px</td><td>down 78 px, left 7 px</td><td style="text-align:right;">30.435</td></tr>
                    <tr><td>lugano</td><td>up 40 px, right 15 px</td><td>down 53 px, left 13 px</td><td style="text-align:right;">30.780</td></tr>
                    <tr><td>melons</td><td>up 81 px, left 10 px</td><td>down 96 px, right 4 px</td><td style="text-align:right;">31.156</td></tr>
                    <tr><td>monastery</td><td>down 3 px, left 2 px</td><td>down 6 px, right 1 px</td><td style="text-align:right;">0.377</td></tr>
                    <tr><td>self_portrait</td><td>up 78 px, left 29 px</td><td>down 98 px, right 8 px</td><td style="text-align:right;">30.837</td></tr>
                    <tr><td>siren</td><td>up 48 px, right 6 px</td><td>down 47 px, left 18 px</td><td style="text-align:right;">32.307</td></tr>
                    <tr><td>three_generations</td><td>up 50 px, left 15 px</td><td>down 58 px, left 4 px</td><td style="text-align:right;">30.443</td></tr>
                    <tr><td>tobolsk</td><td>down 3 px, left 3 px</td><td>down 4 px</td><td style="text-align:right;">0.387</td></tr>
                </tbody>
            </table>
            <h4 style="margin-top:16px;">Additional Results ‚Äî Prokudin‚ÄëGorskii Collection (my selections)</h4>
            <div class="grid">
                <figure><img src="./1_extra/city.png" alt="Prokudin-Gorskii extra - city" /><figcaption>city (collection)</figcaption></figure>
                <figure><img src="./1_extra/gate.png" alt="Prokudin-Gorskii extra - gate" /><figcaption>gate (collection)</figcaption></figure>
                <figure><img src="./1_extra/tippy.png" alt="Prokudin-Gorskii extra - tippie" /><figcaption>tippie (collection ‚Äî downloaded picture was already aligned, my algorithm found the same alignment, as no extra borders around are visible)</figcaption></figure>
                <figure><img src="./1_extra/water.png" alt="Prokudin-Gorskii extra - water" /><figcaption>water (collection)</figcaption></figure>
            </div>
        </section>

        <section class="card glass">
            <h2>Bells &amp; Whistles Results</h2>
            <p>Below are result summaries for each enhancement, with brief approach notes and before/after comparisons.</p>
        </section>

        <section class="card glass">
            <h3>Automatic cropping</h3>
            <p><strong>Intuition</strong>: Real borders sit at the edges, look like long straight lines, and contain lots of extreme pixels ‚Äî very bright (white) and very dark (black). In contrast, real scene content has mixed mid‚Äëtones and broken/curvy edges; full rows or columns in the interior are rarely dominated by extremes, which makes border lines easy to spot.</p>
            <p><strong>Method</strong>:</p>
            <ul>
                <li><strong>Scan full lines</strong>: For left/right, examine vertical lines (columns) spanning the full height; for top/bottom, examine horizontal lines (rows) spanning the full width.</li>
                <li><strong>Classify pixels</strong>: Mark a pixel as black if ‚â§ <em>BLACK_THR</em> and white if ‚â• <em>WHITE_THR</em>. Thresholds are auto‚Äëestimated from a thin outer strip when enabled, otherwise use <em>WHITE_THR ‚âà 0.85</em> and <em>BLACK_THR ‚âà 0.22</em>.</li>
                <li><strong>Score each line</strong>: Compute the fraction of pixels on that line that are extreme (black or white). If the fraction ‚â• <em>70%</em>, classify that line as border.</li>
                <li><strong>Step inward robustly</strong>: Move inward while there is <em>4‚Äëof‚Äë5 neighbor</em> agreement that consecutive lines are border (reduces noise/outliers).</li>
                <li><strong>Safety cap</strong>: Never crop more than <em>45%</em> from any side, and do this per channel (B/G/R) to avoid color bias.</li>
            </ul>
            <p class="muted">As visible below, applying the procedure independently to each channel (B/G/R) produces consistently good crop boxes.</p>
            <p class="muted">Limitation: in some cases, adjacent strong whites and blacks can blend (e.g., via blur/compression/downsampling) into gray along a line, weakening the extreme‚Äëpixel signal and causing under‚Äëdetection of borders. The 4‚Äëof‚Äë5 neighbor voting and per‚Äëchannel processing help, but are not perfect; tightening thresholds or the extreme‚Äëfraction can further improve those edge cases.</p>
            <div class="two-up">
                <figure style="flex:1 1 0; margin:0;">
                    <img src="./2/cathedral_B.png" alt="Per-channel crop box (cathedral, B)" style="display:block;max-width:100%;height:auto;border-radius:12px; outline: 2px solid #0f172a; outline-offset: 4px;" />
                    <figcaption class="muted" style="text-align:center;margin-top:6px;">Cathedral ‚Äî B channel (red box = crop)</figcaption>
                </figure>
                <figure style="flex:1 1 0; margin:0;">
                    <img src="./2/cathedral_G.png" alt="Per-channel crop box (cathedral, G)" style="display:block;max-width:100%;height:auto;border-radius:12px; outline: 2px solid #0f172a; outline-offset: 4px;" />
                    <figcaption class="muted" style="text-align:center;margin-top:6px;">Cathedral ‚Äî G channel (red box = crop)</figcaption>
                </figure>
                <figure style="flex:1 1 0; margin:0;">
                    <img src="./2/cathedral_R.png" alt="Per-channel crop box (cathedral, R)" style="display:block;max-width:100%;height:auto;border-radius:12px; outline: 2px solid #0f172a; outline-offset: 4px;" />
                    <figcaption class="muted" style="text-align:center;margin-top:6px;">Cathedral ‚Äî R channel (red box = crop)</figcaption>
                </figure>
            </div>
            
        </section>

        <section class="card glass">
            <h3>Automatic contrasting</h3>
            <h4>Motivation</h4>
            <p>Global methods (min‚Äìmax scaling or vanilla histogram equalization) can either leave low‚Äëcontrast regions flat or push highlights/shadows too far. Many Prokudin‚ÄëGorskii images have locally varying illumination; we need a method that enhances texture and structure region‚Äëby‚Äëregion without amplifying noise or creating halos.</p>
            <h4>Approach</h4>
            <ul>
                <li><strong>What it is</strong>: Contrast Limited Adaptive Histogram Equalization (CLAHE) boosts local contrast using small tiles and clipped histograms.</li>
                <li><strong>Why histograms help</strong>: A histogram is a simple bar chart of how many pixels have each brightness (0‚Äì255). If most bars sit in a narrow range (e.g., mostly dark), the tile looks flat; spreading tones out across the range reveals hidden detail without changing the scene.</li>
                <li><strong>Color space</strong>: Convert the image to <strong>LAB</strong> and operate on the <strong>L (luminance)</strong> channel only; <em>A/B</em> (color) channels are left unchanged and merged back after equalization to preserve hues.</li>
                <li><strong>How it works</strong>:
                    <ul>
                        <li><strong>Divide into tiles</strong>: Split the image into an <strong>N√óN grid</strong> (configurable; e.g., <strong>24√ó24</strong> here).</li>
                        <li><strong>Build a histogram</strong>: For each tile, count pixels at each brightness (0‚Äì255). This shows how tones are distributed.</li>
                        <li><strong>Clip tall bins</strong>: Set a per‚Äëbin threshold as <em>T √ó (average count per bin)</em> (with <em>T ‚âà 2.0</em>). Cap bars above this level and <em>redistribute the excess uniformly</em> to avoid over‚Äëamplifying noise or small peaks.</li>
                        <li><strong>Equalize via CDF</strong>: The CDF is a running total of the histogram; for any brightness <em>x</em> it tells you what fraction of pixels in this tile are ‚â§ <em>x</em>. We map <em>x ‚Üí CDF(x)</em> (normalized to 0‚Äì1), so darkest values go near 0, brightest near 1, and crowded ranges are spread out ‚Äî revealing detail and increasing local contrast.</li>
                        <li><strong>Blend between tiles</strong>: Each tile yields its own remapping curve. For pixels near tile borders, we take the four surrounding tiles‚Äô curves and combine them with bilinear weights based on the pixel‚Äôs relative (x,y) position (weights sum to 1). The pixel is remapped by this weighted average, which removes visible seams between tiles.</li>
                    </ul>
                </li>
                <li><strong>Luminance‚Äëonly</strong>: Equalization is applied to the <strong>L</strong> channel, then converted back to BGR; this preserves color fidelity while enhancing local detail.</li>
                <li><strong>Trade‚Äëoffs</strong>: Larger tiles ‚Üí smoother, more global look; smaller tiles ‚Üí stronger local contrast but risk amplifying noise if <em>T</em> is too high.</li>
            </ul>
            <h4>Before &amp; After Results</h4>
            <div class="two-up">
                <div class="compare" data-compare>
                    <img class="compare-base" src="./3_contrast/lugano_old.png" alt="Original contrast (Lugano)" />
                    <div class="compare-overlay" style="clip-path: inset(0 0 0 50%)">
                        <img src="./3_contrast/lugano_new.png" alt="Enhanced contrast (Lugano)" />
                    </div>
                    <div class="compare-handle" style="left:50%"></div>
                    <span class="compare-label left">Original</span>
                    <span class="compare-label right">Enhanced</span>
                </div>
                <div class="compare" data-compare>
                    <img class="compare-base" src="./3_contrast/self_portrait_old.png" alt="Original contrast (Self Portrait)" />
                    <div class="compare-overlay" style="clip-path: inset(0 0 0 50%)">
                        <img src="./3_contrast/self_portrait_new.png" alt="Enhanced contrast (Self Portrait)" />
                    </div>
                    <div class="compare-handle" style="left:50%"></div>
                    <span class="compare-label left">Original</span>
                    <span class="compare-label right">Enhanced</span>
                </div>
            </div>
            <p class="muted">The enhanced versions breathe noticeably more contrast and clarity, giving a crisper, more lifelike appearance; by comparison, the originals feel slightly soft and subdued.</p>
            
        </section>

        <section class="card glass">
            <h3>Automatic white balance</h3>
            <h4>Motivation</h4>
            <p>Channels often have different gains/illumination, leading to color casts (e.g., blue/green tint). We aim to estimate a neutral illuminant and re-scale channels so neutrals appear gray/white.</p>
            <h4>Approach</h4>
            <p><strong>Gray‚ÄëWorld algorithm</strong>. Intuition: under a neutral illuminant, the spatial average of an image should be achromatic (gray). If an image has a color cast, the per‚Äëchannel means differ; we correct this by scaling each channel so their means match a common gray target.</p>
            <ul>
                <li><strong>Compute means</strong>: \(\mu_R,\ \mu_G,\ \mu_B\) over interior pixels (optionally exclude borders/outliers).</li>
                <li><strong>Choose gray target</strong>: I use the <em>average of the channel means</em>, \(\mu_{\text{target}} = (\mu_R + \mu_G + \mu_B)/3\).</li>
                <li><strong>Scale channels</strong>: apply gains \(s_c = \mu_{\text{target}} / \mu_c\) to each channel \(c \in \{R,G,B\}\), then clip to the display range.</li>
            </ul>
            <div class="formula">\[ s_c = \frac{\mu_{\text{target}}}{\mu_c}, \quad X'_c = \operatorname{clip}(s_c \cdot X_c) \]</div>
            <p>This neutralizes global color casts while preserving relative contrasts; using interior pixels and clipping avoids bias from borders and outliers.</p>
            <p class="muted">Implementation note: I used the <strong>average-of-means</strong> gray target \(\mu_{\text{target}} = (\mu_R+\mu_G+\mu_B)/3\) (not a fixed 0.5), and clipped per-channel gains to a safe range before applying them.</p>
            <h4>Before &amp; After Results</h4>
            <div class="two-up">
                <div class="compare" data-compare>
                    <img class="compare-base" src="./4_white-balance/emir_old.png" alt="Original white balance (Emir)" />
                    <div class="compare-overlay" style="clip-path: inset(0 0 0 50%)">
                        <img src="./4_white-balance/emir_new.png" alt="White-balanced result (Emir)" />
                    </div>
                    <div class="compare-handle" style="left:50%"></div>
                    <span class="compare-label left">Original</span>
                    <span class="compare-label right">White-balanced</span>
                </div>
                <div class="compare" data-compare>
                    <img class="compare-base" src="./4_white-balance/church_old.png" alt="Original white balance (Church)" />
                    <div class="compare-overlay" style="clip-path: inset(0 0 0 50%)">
                        <img src="./4_white-balance/church_new.png" alt="White-balanced result (Church)" />
                    </div>
                    <div class="compare-handle" style="left:50%"></div>
                    <span class="compare-label left">Original</span>
                    <span class="compare-label right">White-balanced</span>
                </div>
            </div>
            <p class="muted">Assuming the Emir‚Äôs hat and the church facade are meant to be white, the Gray‚ÄëWorld correction makes these regions appear white in the new images‚Äîwhereas they showed clear color casts in the originals.</p>
            
        </section>

        <section class="card glass">
            <h3>Better color mapping</h3>
            <h4>Motivation</h4>
            <p>Channel gains and spectral responses can differ; simple per‚Äëchannel scaling (white balance) may not fully capture cross‚Äëchannel interactions. I explored small color transforms to find a mapping that looks most realistic.</p>
            <h4>Approach</h4>
            <p>I generated a small set of candidates using two tiny 3√ó3 matrix families ‚Äî diagonal channel gains and cross‚Äëchannel mixing ‚Äî then picked the most natural‚Äëlooking result.</p>
            <ul>
                <li><strong>Color basis (additive RGB)</strong>: Red + Green = Yellow (warm), Green + Blue = Cyan (cool), Red + Blue = Magenta. Scaling channels nudges colors along these axes.</li>
                <li><strong>Diagonal gains (warm RG+, cool BG+, magenta RB+)</strong>: Multiply channels independently (diagonal matrix). For example:
                    <ul>
                        <li><em>RG+</em>: boost R and G slightly (~0.28) ‚Üí warmer/yellowish look.</li>
                        <li><em>BG+</em>: boost B and G ‚Üí cooler/cyan look.</li>
                        <li><em>RB+</em>: boost R and B ‚Üí magenta tint.</li>
                    </ul>
                    Also include single‚Äëchannel tweaks (+R, +G, +B and their negatives) to correct specific casts.
                </li>
                <li><strong>Cross‚Äëchannel mixes</strong>: Add a small fraction <em>Œµ ‚âà 0.25</em> from one channel into another (off‚Äëdiagonal entries). Example: <em>B' = (1‚àíŒµ)¬∑B + Œµ¬∑G</em> shifts blue slightly toward cyan, reducing magenta casts; similarly <em>R' ‚Üê R + Œµ¬∑G</em>, <em>G' ‚Üê G + Œµ¬∑B</em>, etc.</li>
                <li><strong>Baselines</strong>: Diagonal gray‚Äëworld and white‚Äëpatch gains for reference.</li>
                <li><strong>Evaluation</strong>: Render candidates to sRGB, size‚Äëmatch, and lay out in a grid to judge realism (skin tones, skies, foliage) side‚Äëby‚Äëside.</li>
            </ul>
            <p class="muted">Note: these mappings are not universal. The most natural‚Äëlooking transform is image‚Äëdependent (scene/illuminant) and therefore relative; the grid enables per‚Äëimage selection rather than a single fixed mapping.</p>
            <h4>Chosen mapping (bottom‚Äëright tile)</h4>
            <p>I picked the bottom‚Äëright tile of the grid as the final mapping. This corresponds to a subtle <em>blue‚Äëfrom‚Äëgreen</em> mix:</p>
            <div class="formula">\[ B' = (1-\varepsilon)\,B + \varepsilon\,G, \quad G' = G, \quad R' = R, \;\; \text{with } \varepsilon \approx 0.25. \]</div>
            <p>Intuition: adding a touch of green into blue reduces residual magenta casts and improves foliage/sky balance without over‚Äësaturating reds.</p>
            <h4 style="margin-top:12px;">Grid and comparison (tippie)</h4>
            <div class="two-up">
                <figure style="flex:1 1 0; margin:0;">
                    <img src="./5/tippy_grid.png" alt="Color mapping variant grid for tippie" style="display:block;max-width:100%;height:auto;border-radius:12px;" />
                    <figcaption class="muted" style="text-align:center;margin-top:6px;">Variant grid (tippie)</figcaption>
                </figure>
                <div class="compare" data-compare>
                    <img class="compare-base" src="./5/tippy_old.png" alt="Tippie before color mapping" />
                    <div class="compare-overlay" style="clip-path: inset(0 0 0 50%)">
                        <img src="./5/tippy_new.png" alt="Tippie after chosen color mapping" />
                    </div>
                    <div class="compare-handle" style="left:50%"></div>
                    <span class="compare-label left">Original</span>
                    <span class="compare-label right">Mapped</span>
                </div>
            </div>
            <p class="muted" style="text-align:center;margin-top:6px;">The mapped image (right) looks more realistic and less like a warm filter is applied (as the left side feels). The sand color also appears more natural.</p>
        </section>

        <section class="card glass">
            <h3>Better features</h3>
            <h4>Gradient-based approach</h4>
            <p>Intuition: edges are places where neighboring pixels differ strongly. Compute horizontal and vertical finite differences, then combine them into a gradient magnitude and normalize. This captures structure while being less sensitive to absolute brightness.</p>
            <div class="formula">\[ G_x(x,y) = I(x+1,y) - I(x-1,y), \quad G_y(x,y) = I(x,y+1) - I(x,y-1) \]</div>
            <div class="formula">\[ |\nabla I|(x,y) = \sqrt{ G_x(x,y)^2 + G_y(x,y)^2 }, \quad \hat G = \frac{|\nabla I| - \mu}{\sigma} \]</div>
            <ul>
                <li><strong>Computation</strong>: For each channel independently, apply the finite differences above, form the magnitude, min‚Äìmax to [0,1] if needed, then z‚Äënormalize (zero mean, unit variance).</li>
                <li><strong>Why it helps</strong>: Gradients emphasize shared structure across channels while down‚Äëweighting absolute intensity/gain differences.</li>
            </ul>
            <h4>Alignment</h4>
            <p>For each candidate shift, I evaluate <strong>equal‚Äëweight NCC and L2</strong> on the gradient maps and pick the best shift in a coarse‚Äëto‚Äëfine pyramid (same window schedule as before).</p>
            <div class="two-up">
                <figure style="flex:1 1 0;">
                    <img class="expandable" src="./6_edges/church_edges_B.png" alt="Church gradient map (Blue channel)" style="display:block;max-width:320px;width:100%;height:auto;border-radius:12px;margin:0 auto;" />
                    <figcaption class="muted" style="text-align:center;margin-top:6px;">Gradient map ‚Äî Blue channel</figcaption>
                </figure>
                <figure style="flex:1 1 0;">
                    <img class="expandable" src="./6_edges/church_edges_G.png" alt="Church gradient map (Green channel)" style="display:block;max-width:320px;width:100%;height:auto;border-radius:12px;margin:0 auto;" />
                    <figcaption class="muted" style="text-align:center;margin-top:6px;">Gradient map ‚Äî Green channel</figcaption>
                </figure>
            </div>
            <p class="muted" style="margin-top:8px;">These gradient maps are used directly for alignment: the algorithm aligns on gradients (not raw intensities) using equal‚Äëweight NCC and L2.</p>
            <div style="display:flex;justify-content:center;margin-top:12px;">
                <img class="expandable" src="./6_edges/church.png" alt="Aligned RGB result (church)" style="display:block;max-width:520px;width:100%;height:auto;border-radius:12px;" />
            </div>
            <p class="muted" style="margin-top:8px;">Finding: On this dataset, gradients+NCC/L2 did <strong>not</strong> outperform the prior method in a significant way, but it was a useful experiment that confirmed alignment robustness to brightness changes.</p>
        </section>

        

        
    </div>
    <div id="lightbox" class="lightbox" aria-hidden="true" role="dialog" aria-label="Expanded image viewer">
        <button class="close" aria-label="Close">√ó</button>
        <img alt="Expanded result" src="" />
    </div>
    <script>
    (function(){
        function init(el){
            var overlay = el.querySelector('.compare-overlay');
            var handle = el.querySelector('.compare-handle');
            if(!overlay || !handle) return;
            var dragging = false;
            function setX(clientX){
                var r = el.getBoundingClientRect();
                var pct = (clientX - r.left) / r.width;
                if (pct < 0) pct = 0; if (pct > 1) pct = 1;
                var perc = (pct*100).toFixed(2) + '%';
                overlay.style.clipPath = 'inset(0 0 0 calc(' + perc + '))';
                handle.style.left = perc;
            }
            function onDown(e){ dragging = true; e.preventDefault(); }
            function onMove(e){ if(!dragging) return; setX(e.clientX || (e.touches && e.touches[0].clientX)); }
            function onUp(){ dragging = false; }
            handle.addEventListener('mousedown', onDown);
            window.addEventListener('mousemove', onMove);
            window.addEventListener('mouseup', onUp);
            handle.addEventListener('touchstart', onDown, {passive:false});
            window.addEventListener('touchmove', onMove, {passive:false});
            window.addEventListener('touchend', onUp);
            el.addEventListener('click', function(e){ setX(e.clientX); });
        }
        document.querySelectorAll('[data-compare]').forEach(init);
    })();
    (function(){
        var lb = document.getElementById('lightbox');
        if(!lb) return;
        var lbImg = lb.querySelector('img');
        var closeBtn = lb.querySelector('.close');
        function open(src, alt){ lbImg.src = src; lbImg.alt = alt || 'Expanded result'; lb.classList.add('open'); lb.setAttribute('aria-hidden','false'); }
        function close(){ lb.classList.remove('open'); lb.setAttribute('aria-hidden','true'); lbImg.src = ''; }
        document.addEventListener('click', function(e){
            var img = e.target.closest('.grid img, .two-up.hero img, .compare img, .expandable');
            if(img){ open(img.getAttribute('src'), img.getAttribute('alt')); }
        });
        closeBtn.addEventListener('click', close);
        lb.addEventListener('click', function(e){ if(e.target === lb) close(); });
        window.addEventListener('keydown', function(e){ if(e.key === 'Escape') close(); });
    })();
    </script>
</body>
</html>